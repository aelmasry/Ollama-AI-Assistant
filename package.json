{
  "name": "vscode-ollama-assistant",
  "displayName": "Ollama AI Assistant",
  "description": "VS Code extension that integrates with locally hosted Ollama models for code improvements and assistance create by Ali Salem",
  "version": "1.0.0",
  "publisher": "alisalem",
  "engines": {
    "vscode": "^1.60.0"
  },
  "categories": [
    "Programming Languages",
    "Machine Learning",
    "Other"
  ],
  "activationEvents": [
    "onStartupFinished",
    "onLanguage:typescript",
    "onLanguage:javascript"
  ],
  "main": "./dist/extension.js",
  "contributes": {
    "commands": [
      {
        "command": "ollamaAI.improveCode",
        "title": "Ollama AI: Improve Selected Code"
      },
      {
        "command": "ollamaAI.explainCode",
        "title": "Ollama AI: Explain Selected Code"
      },
      {
        "command": "ollamaAI.refactorCode",
        "title": "Ollama AI: Suggest Refactoring"
      }
    ],
    "menus": {
      "editor/context": [
        {
          "when": "editorHasSelection",
          "command": "ollamaAI.improveCode",
          "group": "Ollama AI"
        },
        {
          "when": "editorHasSelection",
          "command": "ollamaAI.explainCode",
          "group": "Ollama AI"
        },
        {
          "when": "editorHasSelection",
          "command": "ollamaAI.refactorCode",
          "group": "Ollama AI"
        }
      ]
    },
    "configuration": {
      "title": "Ollama AI Assistant",
      "properties": {
        "ollamaAI.endpoint": {
          "type": "string",
          "default": "http://localhost:11434/api/generate",
          "description": "Ollama API endpoint URL"
        },
        "ollamaAI.model": {
          "type": "string",
          "default": "deepseek-coder:6.7b",
          "description": "Ollama model to use (e.g. deepseek-coder:6.7b, codellama, etc.)"
        },
        "ollamaAI.maxTokens": {
          "type": "number",
          "default": 2048,
          "description": "Maximum tokens to generate in response"
        },
        "ollamaAI.temperature": {
          "type": "number",
          "default": 0.2,
          "description": "Model temperature (0.0 to 1.0, lower is more deterministic)"
        },
        "ollamaAI.contextWindow": {
          "type": "number",
          "default": 20000,
          "description": "Maximum context window size"
        }
      }
    }
  },
  "scripts": {
    "vscode:prepublish": "npm run package",
    "compile": "webpack",
    "watch": "webpack --watch",
    "package": "webpack --mode production --devtool hidden-source-map",
    "compile-tests": "tsc -p . --outDir out",
    "watch-tests": "tsc -p . -w --outDir out",
    "pretest": "npm run compile-tests && npm run compile && npm run lint",
    "lint": "eslint src --ext ts",
    "test": "node ./out/test/runTest.js",
    "build-install": "vsce package && code --install-extension vscode-ollama-assistant-0.1.0.vsix"
  },
  "devDependencies": {
    "@types/glob": "^7.1.3",
    "@types/mocha": "^8.2.2",
    "@types/node": "14.x",
    "@types/vscode": "^1.60.0",
    "@typescript-eslint/eslint-plugin": "^4.26.0",
    "@typescript-eslint/parser": "^4.26.0",
    "eslint": "^7.27.0",
    "glob": "^7.1.7",
    "mocha": "^8.4.0",
    "ts-loader": "^9.2.2",
    "typescript": "^4.3.2",
    "vscode-test": "^1.5.2",
    "webpack": "^5.38.1",
    "webpack-cli": "^4.7.0"
  },
  "dependencies": {
    "axios": "^1.8.1"
  },
  "keywords": [],
  "author": "Ali Salem <admin@alisalem>",
  "license": "ISC"
}